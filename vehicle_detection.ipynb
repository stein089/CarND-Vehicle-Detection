{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import pylab as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import collections\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lesson functions\n",
    "\n",
    "In the lesson_functions, contain all the functions defined during the lesson of the Udacity class.\n",
    "  * get_hog_features()\n",
    "  * bin_spatial()\n",
    "  * color_hist()\n",
    "  * extract_features()\n",
    "  * slide_window()\n",
    "  * draw_boxes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Debug class - used to control debug outputs during execution in a convenient way \n",
    "class Debug():\n",
    "    def __init__(self, \n",
    "                 my_debug_write = False, \n",
    "                 my_debug_plot = False,                  \n",
    "                 my_image_output_folder='test_images_output/',\n",
    "                 my_image_filename_post='',    \n",
    "                ):\n",
    "        \n",
    "        self.debug_write = my_debug_write;  \n",
    "        self.debug_plot = my_debug_plot; \n",
    "        self.image_output_folder = my_image_output_folder;\n",
    "        self.image_filename_post = my_image_filename_post; # post_filename for image_output\n",
    "        \n",
    "        if not os.path.exists(self.image_output_folder):\n",
    "            os.makedirs(self.image_output_folder)\n",
    "        \n",
    "    def my_debug_out(self, img, shortname, is_gray=False, colorspace='RGB'):\n",
    "        if (self.debug_plot): # Plot Image on screen\n",
    "            plt.figure()\n",
    "            if(is_gray == True):\n",
    "                plt.imshow(img, cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(img)\n",
    "            plt.title(shortname, fontsize=25)\n",
    "            \n",
    "        # Write image to output_folder\n",
    "        if (self.debug_write):\n",
    "            if(is_gray == False):\n",
    "                cv2.imwrite(self.image_output_folder  + shortname + self.image_filename_post + '.jpg', cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "            else:\n",
    "                cv2.imwrite(self.image_output_folder  + shortname + self.image_filename_post + '.jpg', img)\n",
    "                \n",
    "    def my_histogram_out(self, hist, bin_centers, shortname):\n",
    "        if (self.debug_plot == True or self.debug_write == True):\n",
    "            fig = plt.figure()\n",
    "            plt.bar(bin_centers, hist[0], width=2)\n",
    "            plt.xlim(0, 256)\n",
    "            plt.title(shortname)\n",
    "            \n",
    "            # Write image to output_folder\n",
    "            if (self.debug_write):\n",
    "                plt.savefig(self.image_output_folder  + shortname + self.image_filename_post + '.jpg')\n",
    "\n",
    "            if (self.debug_plot == False): # Plot Image on screen\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class used to extract features from the training images and providing methods \n",
    "\n",
    "class FeatureExtractor():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.my_debug = Debug(my_debug_write = False,\n",
    "                              my_debug_plot = False,\n",
    "                              my_image_output_folder='test_images_output/')\n",
    "        self.color_space = 'RGB'\n",
    "        self.spatial_size= (32, 32)\n",
    "        self.hist_bins=32\n",
    "        self.orient=9\n",
    "        self.pix_per_cell=8\n",
    "        self.cell_per_block=2\n",
    "        self.hog_channel=0\n",
    "        self.transform_sqrt=False\n",
    "        self.spatial_feat=True\n",
    "        self.hist_feat=True\n",
    "        self.hog_feat=True\n",
    "        \n",
    "    # Based on code from Udacity Online Class\n",
    "    # Define a function to return HOG features and visualization\n",
    "    def get_hog_features(self, img, visualize = False, feature_vector=True):\n",
    "        # Call with two outputs if vis==True\n",
    "       \n",
    "        if (visualize):\n",
    "            features, hog_image = hog(img, orientations=self.orient, \n",
    "                                      pixels_per_cell=(self.pix_per_cell, self.pix_per_cell),\n",
    "                                      cells_per_block=(self.cell_per_block, self.cell_per_block), \n",
    "                                      transform_sqrt=self.transform_sqrt, \n",
    "                                      visualise=visualize, feature_vector=feature_vector)\n",
    "            return features, hog_image\n",
    "        else:\n",
    "            features = hog(img, orientations=self.orient, \n",
    "                            pixels_per_cell=(self.pix_per_cell, self.pix_per_cell),\n",
    "                            cells_per_block=(self.cell_per_block, self.cell_per_block), \n",
    "                            transform_sqrt=self.transform_sqrt, \n",
    "                            visualise=visualize, feature_vector=feature_vector)\n",
    "            return features\n",
    "        \n",
    "\n",
    "    # Based on code from Udacity Online Class\n",
    "    def bin_spatial(self, img):\n",
    "        # Use cv2.resize().ravel() to create the feature vector\n",
    "        bin_spatial_img = cv2.resize(img, self.spatial_size)\n",
    "        features = bin_spatial_img.ravel()\n",
    "        # Return the feature vector\n",
    "        return features, bin_spatial_img\n",
    "\n",
    "    # Based on code from Udacity Online Class\n",
    "    def color_hist(self, img):\n",
    "        # Compute the histogram of the color channels separately\n",
    "        channel1_hist = np.histogram(img[:,:,0], bins=self.hist_bins, range=(0, 256))\n",
    "        channel2_hist = np.histogram(img[:,:,1], bins=self.hist_bins, range=(0, 256))\n",
    "        channel3_hist = np.histogram(img[:,:,2], bins=self.hist_bins, range=(0, 256))\n",
    "        # Concatenate the histograms into a single feature vector\n",
    "        hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "\n",
    "        # Generating bin centers\n",
    "        bin_edges = channel1_hist[1]\n",
    "        bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "\n",
    "        return hist_features, channel1_hist, channel2_hist, channel3_hist, bin_centers\n",
    "    \n",
    "    # Based on code from Udacity Online Class\n",
    "    def convert_color(self, img):\n",
    "        if self.color_space == 'RGB':\n",
    "            feature_image = img.copy()\n",
    "        elif self.color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif self.color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif self.color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif self.color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif self.color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            assert(False, 'Problem')\n",
    "        return feature_image\n",
    "    \n",
    "    \n",
    "    # Based on code from Udacity Online Class\n",
    "    # This function is very similar to extract_features()\n",
    "    # just for a single image rather than list of images\n",
    "    def single_img_features(self, img):    \n",
    "        \n",
    "        self.my_debug.my_debug_out(img, shortname='01_input_img', is_gray=False)\n",
    "        \n",
    "        #1) Define an empty list to receive features\n",
    "        img_features = []\n",
    "        #2) Apply color conversion \n",
    "        feature_image = self.convert_color(img)\n",
    "        \n",
    "        self.my_debug.my_debug_out(feature_image[:,:,0], shortname='01_input_ch0', is_gray=True)\n",
    "        self.my_debug.my_debug_out(feature_image[:,:,1], shortname='01_input_ch1', is_gray=True)\n",
    "        self.my_debug.my_debug_out(feature_image[:,:,2], shortname='01_input_ch2', is_gray=True)    \n",
    "            \n",
    "        #3) Compute spatial features if flag is set\n",
    "        if self.spatial_feat == True:\n",
    "            spatial_features, bin_spatial_img = self.bin_spatial(feature_image)\n",
    "            self.my_debug.my_debug_out(bin_spatial_img[:,:,0], shortname='02_bin_spatial_ch0', is_gray=True)\n",
    "            self.my_debug.my_debug_out(bin_spatial_img[:,:,1], shortname='02_bin_spatial_ch1', is_gray=True)\n",
    "            self.my_debug.my_debug_out(bin_spatial_img[:,:,2], shortname='02_bin_spatial_ch2', is_gray=True)            \n",
    "            #4) Append features to list\n",
    "            img_features.append(spatial_features)\n",
    "            \n",
    "        #5) Compute histogram features if flag is set\n",
    "        if self.hist_feat == True:\n",
    "            hist_features, ch1_hist, ch2_hist, ch3_hist, bin_centers = self.color_hist(feature_image)\n",
    "            \n",
    "            self.my_debug.my_histogram_out(ch1_hist, bin_centers, \"03_hist_ch0\")\n",
    "            self.my_debug.my_histogram_out(ch2_hist, bin_centers, \"03_hist_ch1\")\n",
    "            self.my_debug.my_histogram_out(ch3_hist, bin_centers, \"03_hist_ch2\")\n",
    "            #6) Append features to list\n",
    "            img_features.append(hist_features)\n",
    "            \n",
    "        #7) Compute HOG features if flag is set\n",
    "        if self.hog_feat == True:\n",
    "            if self.hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    ch_features, hog_image_float  = self.get_hog_features(feature_image[:,:,channel], visualize=True, \n",
    "                                                                          feature_vector=True)\n",
    "                    self.my_debug.my_debug_out(hog_image_float*255, shortname='04_hog_ch'+ str(channel), is_gray=True)   \n",
    "                    hog_features.extend(ch_features)      \n",
    "            else:\n",
    "                hog_features, hog_image_float = self.get_hog_features(feature_image[:,:,self.hog_channel], visualize=True, \n",
    "                                                                      feature_vector=True)\n",
    "                self.my_debug.my_debug_out(hog_image_float*255, shortname='04_hog_ch'+ str(self.hog_channel), is_gray=True)   \n",
    "                \n",
    "            #8) Append features to list\n",
    "            img_features.append(hog_features)\n",
    "\n",
    "\n",
    "        #9) Return concatenated array of features\n",
    "        return np.concatenate(img_features)\n",
    "    \n",
    "    # Based on code from Udacity Online Class\n",
    "    def extract_features(self, imgs):\n",
    "        # Create a list to append feature vectors to\n",
    "        features = []\n",
    "        # Iterate through the list of images\n",
    "        for file in imgs:\n",
    "            file_features = []\n",
    "            \n",
    "            # Save filename in order to save files\n",
    "            self.my_debug.image_filename_post = '_' + os.path.splitext(os.path.basename(file))[0]\n",
    "            \n",
    "            # Read in each one by one\n",
    "            image_in = cv2.imread(file) # BGR\n",
    "            image_in = cv2.cvtColor(image_in, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            file_features = self.single_img_features(image_in)   \n",
    "            \n",
    "            features.append(file_features)\n",
    "        # Return list of feature vectors\n",
    "        return features\n",
    "\n",
    "    # From Udacity Online Class\n",
    "    def normalize_features(self, img_features):\n",
    "        X = np.vstack(img_features).astype(np.float64)                        \n",
    "        # Fit a per-column scaler\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "        # Apply the scaler to X\n",
    "        scaled_X = X_scaler.transform(X)\n",
    "        \n",
    "        return scaled_X, X_scaler\n",
    "    \n",
    "    # Based on provided function from Udacity Online Class\n",
    "    # Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "    def find_cars(self, img, ystart, ystop, scale, svc, X_scaler):\n",
    "        #time_start=time.time()\n",
    "        #print('Hello World')\n",
    "        \n",
    "        draw_img = np.copy(img)\n",
    "\n",
    "        img = img[ystart:ystop,:,:]\n",
    "\n",
    "        ctrans_tosearch = self.convert_color(img)\n",
    "\n",
    "        if scale != 1:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "\n",
    "        # Define blocks and steps as above\n",
    "        nxblocks = (ctrans_tosearch[:,:,0].shape[1] // self.pix_per_cell) - self.cell_per_block + 1\n",
    "        nyblocks = (ctrans_tosearch[:,:,0].shape[0] // self.pix_per_cell) - self.cell_per_block + 1 \n",
    "        nfeat_per_block = self.orient*self.cell_per_block**2\n",
    "\n",
    "        #print('nxblocks: ' + str(nxblocks))\n",
    "        #print('nyblocks: ' + str(nyblocks))\n",
    "\n",
    "        # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "        window = 64\n",
    "        nblocks_per_window = (window // self.pix_per_cell) - self.cell_per_block + 1\n",
    "        cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "        # Compute individual channel HOG features for the entire image\n",
    "        \n",
    "        \n",
    "        if (self.hog_channel == 'ALL'):\n",
    "            hog1 = self.get_hog_features(ctrans_tosearch[:,:,0], visualize=False, feature_vector=False)\n",
    "            hog2 = self.get_hog_features(ctrans_tosearch[:,:,1], visualize=False, feature_vector=False)\n",
    "            hog3 = self.get_hog_features(ctrans_tosearch[:,:,2], visualize=False, feature_vector=False)\n",
    "        else:  # eiter 0,1,2\n",
    "            hog_channel = self.get_hog_features(ctrans_tosearch[:,:,self.hog_channel], visualize=False, feature_vector=False)\n",
    "        \n",
    "        box_list = []\n",
    "\n",
    "        #print(round(time.time()-time_start, 2), 's - before loop')\n",
    "        \n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "\n",
    "                #print('  ',round(time.time()-time_start, 4), 's - loop start')\n",
    "                ypos = yb*cells_per_step\n",
    "                xpos = xb*cells_per_step\n",
    "                \n",
    "                \n",
    "                # Extract HOG for this patch\n",
    "                if (self.hog_channel == 'ALL'):\n",
    "                    hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "                else:\n",
    "                    hog_features = hog_channel[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    \n",
    "                #print('  ',round(time.time()-time_start, 4), 's - after hog')\n",
    "                \n",
    "                xleft = xpos*self.pix_per_cell\n",
    "                ytop = ypos*self.pix_per_cell\n",
    "\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "\n",
    "                # Get color features\n",
    "                #print('  ',round(time.time()-time_start, 4), 's - before features')\n",
    "                spatial_features, _ = self.bin_spatial(subimg)\n",
    "                hist_features, _, _, _, _   = self.color_hist(subimg)\n",
    "                #print('  ',round(time.time()-time_start, 4), 's - after features')\n",
    "                # Scale features and make a prediction            \n",
    "                \n",
    "                np.hstack((spatial_features, hist_features, hog_features))\n",
    "                \n",
    "                test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "                test_prediction = svc.predict(test_features)\n",
    "                #print(test_prediction[0])\n",
    "                #print('  ',round(time.time()-time_start, 4), 's - after prediction')\n",
    "\n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    #cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "\n",
    "                    box_list.append(((xbox_left, ytop_draw+ystart), (xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                    \n",
    "                    \n",
    "        #print(round(time.time()-time_start, 2), 's - after loop')\n",
    "        return box_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VehicleDetector():\n",
    "    def __init__(self, svc, X_scaler, feature_extractor):\n",
    "        self.svc = svc\n",
    "        self.X_scaler = X_scaler\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.recent_heats = collections.deque(maxlen=10) \n",
    "        self.my_debug = Debug(my_debug_write = False,\n",
    "                              my_debug_plot = False,\n",
    "                              my_image_output_folder='test_images_output/')\n",
    "    \n",
    "    \n",
    "    def process_image(self, image_in):\n",
    "        \n",
    "        self.my_debug.my_debug_out(img=image_in, shortname='01_image_in')\n",
    "        \n",
    "        \n",
    "        ystart = 400\n",
    "        ystop = 656\n",
    "        \n",
    "        scale = 1\n",
    "        out_boxes = self.feature_extractor.find_cars(image_in, ystart, ystop, scale, self.svc, self.X_scaler)\n",
    "        \n",
    "        scale = 1.33\n",
    "        out_boxes1 = self.feature_extractor.find_cars(image_in, ystart, ystop, scale, self.svc, self.X_scaler)\n",
    "        out_boxes.extend(out_boxes1)\n",
    "        \n",
    "        scale = 1.66\n",
    "        out_boxes2 = self.feature_extractor.find_cars(image_in, ystart, ystop, scale, self.svc, self.X_scaler)\n",
    "        out_boxes.extend(out_boxes2)\n",
    "        \n",
    "        scale = 2\n",
    "        out_boxes3 = self.feature_extractor.find_cars(image_in, ystart, ystop, scale, self.svc, self.X_scaler)\n",
    "        out_boxes.extend(out_boxes3)\n",
    "        \n",
    "        image_boxes = self.draw_boxes(image_in, out_boxes)\n",
    "        self.my_debug.my_debug_out(img=image_boxes, shortname='02_image_boxes', is_gray=False)\n",
    "\n",
    "        heat = np.zeros_like(image_in[:,:,0]).astype(np.float)\n",
    "        heat =  self.add_heat(heat,out_boxes)\n",
    "        self.my_debug.my_debug_out(img=heat, shortname='03_heatmap', is_gray=True)\n",
    "        heat = self.apply_threshold(heat,3)\n",
    "        \n",
    "        self.recent_heats.append(heat)\n",
    "        \n",
    "        heat = np.mean(my_vehicle_detector.recent_heats, axis=0)\n",
    "        heat = self.apply_threshold(heat, 1)\n",
    "\n",
    "        from scipy.ndimage.measurements import label\n",
    "        heatmap = np.clip(heat, 0, 255)\n",
    "        labels = label(heatmap)\n",
    "        draw_img = self.draw_labeled_bboxes(np.copy(image_in), labels)\n",
    "        \n",
    "        self.my_debug.my_debug_out(img=draw_img, shortname='04_out_img', is_gray=False)\n",
    "        \n",
    "        return draw_img\n",
    "    \n",
    "    # From Udacity Online Class\n",
    "    # Define a function to draw bounding boxes\n",
    "    def draw_boxes(self, img, bboxes, color=(0, 0, 255), thick=6):\n",
    "        # Make a copy of the image\n",
    "        imcopy = np.copy(img)\n",
    "        # Iterate through the bounding boxes\n",
    "        for bbox in bboxes:\n",
    "            # Draw a rectangle given bbox coordinates\n",
    "            cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "        # Return the image copy with boxes drawn\n",
    "        return imcopy\n",
    "    \n",
    "    # From Udacity Online Class\n",
    "    def add_heat(self, heatmap, bbox_list):\n",
    "        # Iterate through list of bboxes\n",
    "        for box in bbox_list:\n",
    "            # Add += 1 for all pixels inside each bbox\n",
    "            # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "        # Return updated heatmap\n",
    "        return heatmap\n",
    "    \n",
    "    # From Udacity Online Class\n",
    "    def apply_threshold(self, heatmap, threshold):\n",
    "        # Zero out pixels below the threshold\n",
    "        heatmap[heatmap <= threshold] = 0\n",
    "        heatmap[heatmap > 6] = 6\n",
    "        # Return thresholded map\n",
    "        return heatmap\n",
    "    \n",
    "    \n",
    "    # From Udacity Online Class\n",
    "    def draw_labeled_bboxes(self, img, labels):\n",
    "        # Iterate through all detected cars\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "        # Return the image\n",
    "        return img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Feature Extractor Object and define parameter\n",
    "\n",
    "my_feature_extractor = FeatureExtractor() \n",
    "\n",
    "my_feature_extractor.my_debug.my_image_output_folder='test_images_output/'\n",
    "my_feature_extractor.color_space = 'YCrCb'\n",
    "my_feature_extractor.spatial_size= (16, 16)\n",
    "my_feature_extractor.hist_bins=32\n",
    "my_feature_extractor.orient=9\n",
    "my_feature_extractor.pix_per_cell=8\n",
    "my_feature_extractor.cell_per_block=2\n",
    "my_feature_extractor.hog_channel='ALL'\n",
    "my_feature_extractor.transform_sqrt=False\n",
    "my_feature_extractor.spatial_feat=True\n",
    "my_feature_extractor.hist_feat=True\n",
    "my_feature_extractor.hog_feat=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_images length: 8792\n",
      "notcar_images length: 8968\n"
     ]
    }
   ],
   "source": [
    "##### Load Training Data #### \n",
    "car_dirs = [\"data/vehicles/KITTI_extracted/\", \"data/vehicles/GTI_Far/\", \"data/vehicles/GTI_Left/\", \n",
    "            \"data/vehicles/GTI_MiddleClose/\", \"data/vehicles/GTI_Right/\"]\n",
    "notcar_dirs = [\"data/non-vehicles/GTI/\", \"data/non-vehicles/Extras/\"]\n",
    "\n",
    "\n",
    "car_images = []\n",
    "for my_dir in car_dirs:\n",
    "    car_images.extend(glob.glob(my_dir+'*.png'))\n",
    "\n",
    "notcar_images = []\n",
    "for my_dir in notcar_dirs:\n",
    "    notcar_images.extend(glob.glob(my_dir+'*.png') ) \n",
    "\n",
    "# Shuffle the data within the image arrays\n",
    "random.shuffle(car_images)\n",
    "random.shuffle(notcar_images)\n",
    "\n",
    "print('car_images length:', len(car_images))\n",
    "print('notcar_images length:', len(notcar_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length: 6156\n",
      "[LibLinear]41.25 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9901\n"
     ]
    }
   ],
   "source": [
    "my_feature_extractor.my_debug.debug_plot = False;\n",
    "my_feature_extractor.my_debug.debug_write = False;\n",
    "\n",
    "# Reduce the sample size because\n",
    "# The quiz evaluator times out after 13s of CPU time\n",
    "#sample_size = 1000\n",
    "#car_images = car_images[0:sample_size]\n",
    "#notcar_images = notcar_images[0:sample_size]\n",
    "    \n",
    "    \n",
    "###### FEATURE EXTRACTION #######\n",
    "car_features = my_feature_extractor.extract_features(car_images)\n",
    "notcar_features = my_feature_extractor.extract_features(notcar_images)\n",
    "\n",
    "feature_list = [car_features, notcar_features] \n",
    "\n",
    "scaled_X, X_scaler = my_feature_extractor.normalize_features(feature_list)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "###### TRAIN CLASSIFIER #######\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC(verbose=True)\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_feature_extractor.my_debug.debug_plot = False;\n",
    "my_feature_extractor.my_debug.debug_write = False;\n",
    "\n",
    "test_images_dir = \"test_images/\"\n",
    "test_images = glob.glob(test_images_dir+'*.jpg')  \n",
    "\n",
    "#### Uncomment if only testing one image\n",
    "#test_images = ['test_images/test6.jpg']  \n",
    "    \n",
    "for image_to_read in test_images:\n",
    "    \n",
    "    my_vehicle_detector = VehicleDetector(svc=svc, X_scaler=X_scaler, feature_extractor=my_feature_extractor)\n",
    "    my_vehicle_detector.my_debug.debug_plot = False\n",
    "    my_vehicle_detector.my_debug.debug_write = True\n",
    "\n",
    "    filename_txt = os.path.splitext(os.path.basename(image_to_read))[0]\n",
    "    my_vehicle_detector.my_debug.image_filename_post = '_'  + filename_txt\n",
    "    \n",
    "    image_in = cv2.imread(image_to_read)\n",
    "    image_in = cv2.cvtColor(image_in, cv2.COLOR_BGR2RGB)\n",
    "    im_out = my_vehicle_detector.process_image(image_in)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/project_video.mp4\n",
      "[MoviePy] Writing video test_videos_output/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 100/101 [03:49<00:02,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/project_video.mp4 \n",
      "\n",
      "CPU times: user 3min 49s, sys: 4.34 s, total: 3min 53s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "my_vehicle_detector = VehicleDetector(svc=svc, X_scaler=X_scaler, feature_extractor=my_feature_extractor)\n",
    "my_feature_extractor.my_debug.debug_plot = False;\n",
    "my_feature_extractor.my_debug.debug_write = False;\n",
    "\n",
    "\n",
    "if not os.path.exists('test_videos_output'):\n",
    "    os.makedirs('test_videos_output')\n",
    "white_output = 'test_videos_output/project_video.mp4'\n",
    "    \n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\").subclip(18,22)\n",
    "white_clip = clip1.fl_image(my_vehicle_detector.process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heat = my_vehicle_detector.recent_heats[-7]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(heat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
